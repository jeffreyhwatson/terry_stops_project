Subject Age Group           0
Subject ID                  0
GO / SC Num                 0
Terry Stop ID               0
Stop Resolution             0
Weapon Type                 0
Officer ID                  0
Officer YOB                 0
Officer Gender              0
Officer Race                0
Subject Perceived Race      0
Subject Perceived Gender    0
Reported Date               0
Reported Time               0
Initial Call Type           0
Final Call Type             0
Call Type                   0
Officer Squad               0
Arrest Flag                 0
Frisk Flag                  0
Precinct                    0
Sector                      0
Beat                        0

# getting new column list
column_list = df.columns
column_list

# creating list to check value counts
excluded = ['Officer YOB', 'Initial Call Type',
            'Final Call Type','Call Type', 'Officer Squad']
cols = [x for x in column_list if x not in excluded]

# printing value counts
for col in cols:
    print(f'{df[col].value_counts()}\n')
    
array([0.81246451, 0.80664395, 0.8056502 , 0.80820557, 0.80352073])
array([0.81218058, 0.80337876, 0.80593413, 0.80976718, 0.80053947])

White           0.488735
Black           0.297807
Unknown         0.055515
NA              0.039821
Hispanic        0.035434
Asian           0.032453
N_American      0.028769
Multi-Racial    0.017036
Other           0.003237
P_Islander      0.001193

## KNN With Engineered Features
Engineered columns from original EDA:

'Weapon Flag', 'Reported Year', 'Reported Month', 'Day of Month', 'Day of Week', 'Reported Hour', 'Beat Flag'

feature_list1 = ['Sector',
 'Beat',
 'Weapon Flag',
 'Reported Year',
 'Reported Month',
 'Day of Month',
 'Day of Week',
 'Reported Hour',
 'Beat Flag']
 
 excluded1 = ['Weapon Type',
 'Initial Call Type',
 'Final Call Type',
 'Call Type',
 'Officer Squad',
 'Arrest Flag',
 'Frisk Flag',]
 
 engineered = f.framer(df, feature_list1, excluded1)
 
 f.feature_test(engineered, KNN, feature_list1)
 
 f.feature_test(engineered, LR, feature_list1)
 
 pipe.get_params().keys()
 
 dict_keys(['memory', 'steps', 'verbose', 'columntransformer', 'smote', 'logisticregression', 'columntransformer__n_jobs', 'columntransformer__remainder', 'columntransformer__sparse_threshold', 'columntransformer__transformer_weights', 'columntransformer__transformers', 'columntransformer__verbose', 'columntransformer__onehotencoder', 'columntransformer__standardscaler', 'columntransformer__onehotencoder__categories', 'columntransformer__onehotencoder__drop', 'columntransformer__onehotencoder__dtype', 'columntransformer__onehotencoder__handle_unknown', 'columntransformer__onehotencoder__sparse', 'columntransformer__standardscaler__copy', 'columntransformer__standardscaler__with_mean', 'columntransformer__standardscaler__with_std', 'smote__k_neighbors', 'smote__n_jobs', 'smote__random_state', 'smote__sampling_strategy', 'logisticregression__C', 'logisticregression__class_weight', 'logisticregression__dual', 'logisticregression__fit_intercept', 'logisticregression__intercept_scaling', 'logisticregression__l1_ratio', 'logisticregression__max_iter', 'logisticregression__multi_class', 'logisticregression__n_jobs', 'logisticregression__penalty', 'logisticregression__random_state', 'logisticregression__solver', 'logisticregression__tol', 'logisticregression__verbose', 'logisticregression__warm_start'])
 
def forward_selection(df, target, model):
    remaining = set(df.columns)
    remaining.remove(target)
    selected = []
    current_score, best_new_score = 0.0, 0.0
    
    string_selector = make_column_selector(dtype_include='object')
    number_selector = make_column_selector(dtype_include='number', dtype_exclude='object')
    preprocessing = make_column_transformer((OneHotEncoder
                                             (handle_unknown='ignore'),string_selector),
                                            (StandardScaler(), number_selector))
    
    while remaining and current_score == best_new_score:
            scores_with_candidates = []
    
            for candidate in remaining:
                feature_df = framer(df, [candidate], remaining)
                X, y = Xy(feature_df)
                X_train, X_test, y_train, y_test = splitter(X,y)
                feature_pipe = make_pipeline(preprocessing, model)
                feature_pipe.fit(X_train, y_train)
                score = f1_score(feature_pipe.predict(X_train), y_train)
                scores_with_candidates.append((score, candidate))
            scores_with_candidates.sort()
            best_new_score, best_candidate = scores_with_candidates.pop()
            if current_score < best_new_score:
                remaining.remove(best_candidate)
                selected.append(best_candidate)
                current_score = best_new_score
    feature_df = framer(df, [selected], remaining)
    X, y = Xy(feature_df)
    X_train, X_test, y_train, y_test = splitter(X,y)
    feature_pipe = make_pipeline(preprocessing, model)
    score = f1_score(feature_pipe.predict(X_train), y_train)
    return score
    
class HarnessCCV:
    
    def __init__(self, scorer, random_state=2021):
        self.scorer = scorer
        self.history = pd.DataFrame(columns=['Name', 'Accuracy', 'Notes'])

    def report(self, estimator, X, y, name, notes=''):
        # Create a list to hold the scores from each fold
        kfold_val_scores = np.ndarray(5)
        kfold_train_scores = np.ndarray(5)

        # Instantiate a splitter object and loop over its result
        kfold = StratifiedKFold(n_splits=5)
        for fold, (train_index, val_index) in enumerate(kfold.split(X, y)):
            # Extract train and validation subsets using the provided indices
            X_t, X_val = X.iloc[train_index], X.iloc[val_index]
            y_t, y_val = y.iloc[train_index], y.iloc[val_index]
        
            # Instantiate StandardScaler
            scaler = StandardScaler()
            # Fit and transform X_t
            X_t_scaled = scaler.fit_transform(X_t)
            # Transform X_val
            X_val_scaled = scaler.transform(X_val)
        
            # Instantiate SMOTE
            sm = SMOTE(random_state=2021)
            # Fit and transform X_t_scaled and y_t using sm
            X_t_oversampled, y_t_oversampled = sm.fit_resample(X_t_scaled, y_t)
        
            # Clone the provided model and fit it on the train subset
            temp_model = clone(estimator)
            temp_model.fit(X_t_oversampled, y_t_oversampled)
        
            # Evaluate the model on the validation subsets
            score_train = precision_score(temp_model.predict(X_t_oversampled), y_t_oversampled)
            scores_val = precision_score(temp_model.predict(X_val_scaled), y_val)
            kfold_train_scores[fold] = score_train
            kfold_val_scores[fold] = scores_val
        
        frame = pd.DataFrame([[name, scores_val.mean(), notes]], columns=['Name', 'Accuracy', 'Notes'])
        self.history = self.history.append(frame)
        self.history = self.history.reset_index(drop=True)
        self.history = self.history.sort_values('Accuracy')
        self.print_error(name, scores_val.mean())
        print(kfold_val_scores)
                               
        return kfold_train_scores, kfold_val_scores 

    def print_error(self, name, Accuracy):
        print(f'{name} has an average {scorer} of {Accuracy}')

